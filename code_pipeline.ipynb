{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaanvi-prabhakar/SP-BTT-Patent-Classification/blob/fixes/code_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "view-in-github"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cf098288",
      "metadata": {
        "id": "cf098288"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "import time\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d028e2",
      "metadata": {
        "id": "d0d028e2"
      },
      "outputs": [],
      "source": [
        "industry_keywords = {\n",
        "    \"Digital Healthcare\": [\"remote medical patient monitoring\", \"telemedicine\", \"remote surgery\", \"telehealth\", \"teledentistry\"],\n",
        "    \"Sustainable Farming\": [\"farming technology\", \"precision agriculture\", \"vertical farming\", \"hydroponics\", \"alternative meat\"],\n",
        "    \"Autonomous Vehicles\": [\"self-driving\", \"autonomous vehicle\", \"autonomous car\", \"automated driving\",\n",
        "    \"driverless\", \"automated vehicle\", \"robotic car\", \"intelligent vehicle\", \"vehicle\", \"navigation\", \"transportation\", \"driving\", \"sensors\", \"autonomous\"\n",
        "],\n",
        "    \"Artificial Intelligence\": [\"artificial intelligence\", \"graphics processing unit\", \"large language model\", \"deep learning\"],\n",
        "    \"3D Printing\": [\"3D printer\", \"additive manufacturing\", \"bioprinting\", \"3D scanner\", \"soundwave printing\", \"vehicle\", \"3D print\", \"3D design\", \"3D scan\", \"Additive print\", \"Additive printing\", \"binder jet\", \"3D model\", \"3D modeling\", \"additive manufacture\", \"metal print\", \"metal printing\", \"bioprint\", \"bio-print\", \"bio-printing\", \"Continuous Liquid Interface\", \"deductive manufacturing\", \"deductive manufacture\", \"direct energy deposition\"\n",
        "],\n",
        "    \"Virtual Reality\": [\"virtual reality headset\", \"augmented reality glasses\", \"virtual reality platform\", \"VR software\", \"AR hardware\"],\n",
        "    \"Nanotechnology\": [\"nanoscale material\", \"nanoscale technology\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ckfSpHoGRUbG",
      "metadata": {
        "id": "ckfSpHoGRUbG"
      },
      "source": [
        "## Prompt Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q-z2jNa6-zqR",
      "metadata": {
        "id": "Q-z2jNa6-zqR"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(industry_keywords_dict, industry, abstract, few_shot_examples):\n",
        "    \"\"\"\n",
        "    Generate a prompt for the LLM using few-shot examples and industry keywords.\n",
        "\n",
        "    Args:\n",
        "        industry_keywords_dict (dict): Keywords associated with industries.\n",
        "        abstract (str): Abstract to be classified.\n",
        "\n",
        "    Returns:\n",
        "        str: The full prompt for the LLM.\n",
        "    \"\"\"\n",
        "    # Add few-shot examples to the prompt\n",
        "    examples_text = \"\\nExamples:\\n\"\n",
        "    for example in few_shot_examples[\"samples\"]:\n",
        "        if example['Patent Class'] == industry:  # Only include examples from the current industry\n",
        "\n",
        "          examples_text += f\"\\nPatent Class: {example['Patent Class']}\\n\"\n",
        "          examples_text += f\"Positive Sample: {example['Positive Sample']}\\n\"\n",
        "          examples_text += f\"Negative Sample: {example['Negative Sample']}\\n\"\n",
        "          examples_text += f\"Reason: {example['Reason']}\\n\"\n",
        "\n",
        "    #hard coded for autonomous vehicles, comment below out if doing other categories\n",
        "    examples_text += \"\\nJudgment Call Examples (for Autonomous Vehicles):\\n\"\n",
        "    examples_text += \"\"\"\n",
        "    1. Abstract: An automatic deceleration control apparatus for a vehicle operates so as to secure\n",
        "      appropriate tire grip performance, depending on the conditions of a road surface on which the vehicle runs turning,\n",
        "      and restrain excessive rolling of the vehicle body, there by stabilizing the turning behavior of the vehicle at all times.\n",
        "      While the vehicle is turning on a high-friction road surface without undergoing haw moment control, a safe vehicle speed is\n",
        "      computed within the rollover limit of the vehicle. While the vehicle is turning on a low-friction road surface under haw moment\n",
        "      control, on the other hand, a safe vehicle speed that ensures satisfactory tire grip performance is computed in accordance with an\n",
        "      estimated road friction coefficient. When the vehicle is about to exceed its safe speed as it turns, it is automatically decelerated\n",
        "      to the safe speed or below. Thus, the vehicle can be prevented from spinning, drifting out, or rolling over. (Yes)\n",
        "      Reason: While it describes a control system not exclusive to autonomous driving, it could be applied in autonomous vehicle systems.\n",
        "\n",
        "    2. Abstract: A method and apparatus for warning a driver of a motor vehicle of a predicted collision with a stationary object.\n",
        "    A proximity sensor is used to determine a position of an obstacle relative to the vehicle. A steering angle of the vehicle is\n",
        "    determined and used to predict a trajectory of the vehicle. A collision zone on the vehicle is identified based on the vehicle\n",
        "    trajectory, the collision zone being that spot or location on the vehicle which is predicted to contact the obstacle. A visual\n",
        "    display within the vehicle (on the control panel, for example) provides a visual indication to the driver of the position of the\n",
        "     collision zone on the vehicle and a predicted trajectory of the collision zone as the vehicle moves in accordance with the steering angle. (Yes)\n",
        "       Reason: This system can clearly be applied to autonomous driving, even though it is not solely for that purpose.\n",
        "\n",
        "    3. Abstract: To determine whether an emergency braking situation exists for a vehicle, the vehicle determines at least the\n",
        "    following state variables: its own velocity, its own longitudinal acceleration, its relative distance from an object in front,\n",
        "    and the speed and acceleration of the object in front. A suitable evaluation method to assess whether an emergency braking situation\n",
        "     is present is determined as a function of these state variables from a plurality of evaluation method options, including at least a\n",
        "     movement equation evaluation method in which a movement equation system of the vehicle and of the object in front is determined, and\n",
        "      an evaluation method in which a braking distance of the vehicle is determined. (No)\n",
        "       Reason: The system is too generic and not specific enough to be classified as an autonomous vehicle technology.\n",
        "\n",
        "    4. Abstract: To prevent overbraking of the vehicle rear wheels, brake pressure control\n",
        "    valves are employed comprising essentially a stepped piston and a valve. A control piston\n",
        "    is provided which prevents closing of the valve in the event of failure of a brake circuit.\n",
        "    The prior known arrangements are expensive to manufacture and require a large number of seals.\n",
        "    The invention, therefore, provides a brake pressure control valve in which an annular piston is\n",
        "    provided with a bore which is penetrated by the control piston. A first of the annular piston\n",
        "    transverse surfaces is subjected to the pressure of the front wheel brake circuit while a second\n",
        "     of the annular piston transverse surfaces is subjected to the regulated pressure of the rear wheel\n",
        "     brake circuit. The control piston&#39;s end adjacent the valve bears against the annular piston in\n",
        "     the direction of a control spring. (No)\n",
        "       Reason: The system is too general and unrelated to autonomous vehicles specifically.\n",
        "\n",
        "\n",
        "\n",
        "    5. Abstract: An automotive vehicle includes engine start/stop (ESS) and adaptive cruise control with stop\n",
        "     and go functionality (ACCS&amp;G). A method of coordinating operation of the ESS and ACCS&amp;G systems is\n",
        "     provided. The ACCS&amp;G system brings the vehicle to a stop. After a delay and satisfaction of autostop conditions,\n",
        "     the ESS system stops the engine. Upon receipt of an input and satisfaction of start conditions, the ESS system restarts\n",
        "     the engine. The ACCS&amp;G system then resumes control of the restarted engine.\n",
        "     (No)\n",
        "       Reason: Not a feature of vehicular autonomy\n",
        "\n",
        "\n",
        "    6. Abstract: A traction control system for an automotive vehicle comprises, a brake fluid pressure control actuator\n",
        "    associated with at least driven wheels for reducing traction created through the driven wheels, and sensors for\n",
        "    monitoring an acceleration-slip state of at least one of the driven wheels. A recovery control unit is arranged\n",
        "    for deriving a degree of turn of the vehicle, and for deriving a rate of change in the vehicle turning degree.\n",
        "    The recovery control unit is responsive to the change-rate in the turning degree during an acceleration-slip control,\n",
        "    for controlling traction in a transient state shifting from turning to straight-ahead driving, in such a manner as\n",
        "     to increase a recovery amount of driving torque caused by the driven wheel as the turning degree is weakened. (No)\n",
        "      Reason: Not a feature of vehicular autonomy\n",
        "\n",
        "    7. Abstract: A vehicle monitoring system uses at least one image capture device located\n",
        "     on a vehicle and provides two or more associated images for combined display on an\n",
        "     autostereoscopic display provided adjacent an operator. Preferably the images are\n",
        "     processed for display and provide the operator with visual information that otherwise\n",
        "      may not be available. The invention is directed to both apparatus and method for providing of this information. (Yes)\n",
        "       Reason: This does seem relevant: \"vehicle monitoring system,\" \"image capture device located on a vehicle\"\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the response format and keywords for all topics\n",
        "    response_format = \"\\n\".join([f\"{industry}: [Yes/No]\" for industry in industry_keywords_dict.keys()])\n",
        "    keywords_list = \"\\n\".join([f\"{industry}: {', '.join(keywords)}\" for industry, keywords in industry_keywords_dict.items()])\n",
        "\n",
        "    # Build the full prompt\n",
        "    full_prompt = (\n",
        "        f\"Determine if the following patent abstract is relevant to the category '{industry}' listed below.\\n\"\n",
        "        f\"Answer ONLY with 'Yes' or 'No' for the category.\\n\\n\"\n",
        "        f\"The following is a list of keywords associated with this category to assist you:\\n\"\n",
        "        f\"{', '.join(industry_keywords_dict[industry])}\\n\"\n",
        "        f\"\\n{examples_text}\\n\"\n",
        "        f\"Do NOT include any explanations or extra text. Just the 'Yes' or 'No' answer.\\n\\n\"\n",
        "        f\"Abstract:\\n{abstract}\\n\\n\"\n",
        "    )\n",
        "    return full_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HWppx6wfDI6F",
      "metadata": {
        "id": "HWppx6wfDI6F"
      },
      "source": [
        "## Predict Industry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e8855a",
      "metadata": {
        "id": "d3e8855a"
      },
      "outputs": [],
      "source": [
        "# API KEY setup\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get(\"google_api_key\")\n",
        "except:\n",
        "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize model\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Load few-shot examples from the json file\n",
        "with open('./patent_classification.json', 'r') as file:\n",
        "    few_shot_examples = json.load(file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rsd55m9cYlpX",
      "metadata": {
        "id": "rsd55m9cYlpX"
      },
      "outputs": [],
      "source": [
        "def predict_industry(abstract, industry, keywords, few_shot_examples, max_retries=5, delay=4):\n",
        "    \"\"\"\n",
        "    Classify an abstract using the LLM with the generated prompt.\n",
        "\n",
        "    Args:\n",
        "        abstract (str): Abstract to classify.\n",
        "        industry (str): Name of the industry/category.\n",
        "        keywords (list): Keywords related to the industry.\n",
        "        few_shot_examples (dict): Few-shot examples for prompt construction.\n",
        "        max_retries (int): Maximum number of retries in case of API failure.\n",
        "        delay (int): Delay between retries (in seconds).\n",
        "\n",
        "    Returns:\n",
        "        str: Classification result (\"Yes\" or \"No\").\n",
        "    \"\"\"\n",
        "    full_prompt = generate_prompt(industry_keywords, industry, abstract, few_shot_examples)\n",
        "    attempts = 0\n",
        "    response_text = \"\"\n",
        "\n",
        "\n",
        "    while attempts < max_retries:\n",
        "        try:\n",
        "            # Make a single API call with the refined prompt\n",
        "            response = model.generate_content(full_prompt)\n",
        "            response_text = response.text\n",
        "            break  # Exit loop if request is successful\n",
        "        except Exception as e:\n",
        "            print(f\"API error: {e}, retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            attempts += 1\n",
        "\n",
        "    if attempts == max_retries:\n",
        "        print(f\"Failed to get a response after {max_retries} attempts.\")\n",
        "        return \"No\"\n",
        "\n",
        "\n",
        "\n",
        "    # Match only \"Yes\" or \"No\" as a standalone word in the response\n",
        "    match = re.search(r\"\\b(Yes|No)\\b\", response_text, re.IGNORECASE)\n",
        "    return match.group(1).capitalize() if match else \"No\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fbd0bb1",
      "metadata": {
        "id": "7fbd0bb1"
      },
      "outputs": [],
      "source": [
        "def add_keywords_column(data, keywords):\n",
        "    \"\"\"\n",
        "    Add a column to the dataset indicating whether abstracts contain any of the specified keywords.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Dataset to filter.\n",
        "        keywords (list): List of keywords to search for in the abstracts.\n",
        "\n",
        "    Returns:\n",
        "        None: Modifies the DataFrame in place.\n",
        "    \"\"\"\n",
        "    data['has_keywords'] = data['abstract'].apply(lambda x: 1 if any(keyword.lower() in x.lower() for keyword in keywords) else 0)\n",
        "\n",
        "\n",
        "def prepare_review_table(classified_data):\n",
        "    \"\"\"\n",
        "    Prepare a table for manual review with metadata.\n",
        "\n",
        "    Args:\n",
        "        classified_data (pd.DataFrame): Classified dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Review table ready for export.\n",
        "    \"\"\"\n",
        "\n",
        "    # Rename columns to match expected format for CSV export\n",
        "    classified_data = classified_data.rename(columns={'Patent ID': 'Index', 'abstract': 'Abstract'})\n",
        "\n",
        "    classified_data['Reviewer'] = assign_reviewers(len(classified_data))\n",
        "    classified_data['True label'] = \"\"\n",
        "    classified_data['Comments'] = \"\"\n",
        "    classified_data['Requires expert review'] = False\n",
        "\n",
        "    # Select the relevant columns for the review table\n",
        "    return classified_data[['Index', 'Abstract', 'Reviewer', 'True label', 'Comments', 'Requires expert review']]\n",
        "\n",
        "\n",
        "def assign_reviewers(num_cases):\n",
        "    \"\"\"\n",
        "    Assign reviewers to cases in a round-robin fashion.\n",
        "\n",
        "    Args:\n",
        "        num_cases (int): Number of cases to review.\n",
        "\n",
        "    Returns:\n",
        "        list: Reviewer assignments.\n",
        "    \"\"\"\n",
        "    reviewers = ['Rohan', 'Raymond', 'Lior', 'Jamie', 'Zara', 'Johanna']\n",
        "    return [reviewers[i % len(reviewers)] for i in range(num_cases)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Up6h-HEFM3Pv",
      "metadata": {
        "id": "Up6h-HEFM3Pv"
      },
      "outputs": [],
      "source": [
        "def classify_patents(data, industry, keywords, few_shot_examples, max_positives=5, rpm=15, use_filter=True):\n",
        "    \"\"\"\n",
        "    Classify patents to find relevant abstracts based on the LLM.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Dataset to classify.\n",
        "        industry (str): Name of the industry/category.\n",
        "        keywords (list): Keywords related to the industry.\n",
        "        few_shot_examples (dict): Few-shot examples for prompt construction.\n",
        "        max_positives (int, optional): Maximum number of positive samples to collect. If None, classify all data.\n",
        "        rpm (int): Maximum requests per minute to the API.\n",
        "        use_filter (bool): Whether to filter abstracts by keywords before classification.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dataset with predictions added as a new column.\n",
        "    \"\"\"\n",
        "    positive_count = 0\n",
        "    requests_made = 0\n",
        "    delay_per_request = 60 / rpm  # Calculate delay based on RPM\n",
        "\n",
        "    # Apply keyword filter if specified\n",
        "    if use_filter:\n",
        "        add_keywords_column(data, keywords)\n",
        "        data = data[data['has_keywords'] == 1]\n",
        "        print(f\"Filtered down to {len(data)} abstracts containing relevant keywords.\")\n",
        "\n",
        "    data = data.copy()  # Make a deep copy\n",
        "    data['LLM Prediction'] = \"\"  # Initialize column for predictions\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        if max_positives and positive_count >= max_positives:\n",
        "            print(\"Reached the maximum number of positive samples.\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            prediction = predict_industry(row['abstract'], industry, keywords, few_shot_examples)\n",
        "            data.at[index, 'LLM Prediction'] = prediction\n",
        "            if prediction == \"Yes\":\n",
        "                positive_count += 1\n",
        "\n",
        "            requests_made += 1\n",
        "            # if index % 100 == 0:  # Log every 100 rows\n",
        "            #     print(f\"Processed {index}/{len(data)} rows. Current Positive Count: {positive_count}\")\n",
        "\n",
        "            # Rate limiting\n",
        "            if requests_made % rpm == 0:\n",
        "                print(f\"Reached {rpm} requests. Pausing for 60 seconds to avoid rate limit.\")\n",
        "                time.sleep(60)\n",
        "            else:\n",
        "                time.sleep(delay_per_request)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {index}: {e}\")\n",
        "            data.at[index, 'LLM Prediction'] = \"Error\"\n",
        "            continue\n",
        "\n",
        "    print(f\"Classification completed. Found {positive_count} positive samples.\")\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jLT7tDDTGagi",
      "metadata": {
        "id": "jLT7tDDTGagi"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JpUd5ct3PlpI",
      "metadata": {
        "id": "JpUd5ct3PlpI"
      },
      "outputs": [],
      "source": [
        "def save_balanced_csv(data, file_path, industry_name, max_samples_per_class=60):\n",
        "    \"\"\"\n",
        "    Save a balanced dataset with an equal number of positive and negative samples.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Dataset with predictions.\n",
        "        file_path (str): Path to save the CSV file.\n",
        "        industry_name (str): Industry/category name for the dataset.\n",
        "        max_samples_per_class (int): Maximum number of samples per class.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Balanced dataset.\n",
        "    \"\"\"\n",
        "    positive_samples = data[data[industry_name] == \"Yes\"].sample(n=max_samples_per_class, random_state=1234)\n",
        "    negative_samples = data[data[industry_name] == \"No\"].sample(n=max_samples_per_class, random_state=1234)\n",
        "\n",
        "    balanced_data = pd.concat([positive_samples, negative_samples])\n",
        "    balanced_data.to_csv(file_path, index=False)\n",
        "    return balanced_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RYFxEtk0M4i5",
      "metadata": {
        "id": "RYFxEtk0M4i5"
      },
      "outputs": [],
      "source": [
        "def add_keywords_column(data, keywords):\n",
        "    \"\"\"\n",
        "    Add a column to the dataset indicating whether abstracts contain any of the specified keywords.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Dataset to filter.\n",
        "        keywords (list): List of keywords to search for in the abstracts.\n",
        "\n",
        "    Returns:\n",
        "        None: Modifies the DataFrame in place.\n",
        "    \"\"\"\n",
        "    data['has_keywords'] = data['abstract'].apply(lambda x: 1 if any(keyword.lower() in x.lower() for keyword in keywords) else 0)\n",
        "\n",
        "\n",
        "def prepare_review_table(classified_data):\n",
        "    \"\"\"\n",
        "    Prepare a table for manual review with metadata.\n",
        "\n",
        "    Args:\n",
        "        classified_data (pd.DataFrame): Classified dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Review table ready for export.\n",
        "    \"\"\"\n",
        "\n",
        "    # Rename columns to match expected format for CSV export\n",
        "    classified_data = classified_data.rename(columns={'Patent ID': 'Index', 'abstract': 'Abstract'})\n",
        "\n",
        "    classified_data['Reviewer'] = assign_reviewers(len(classified_data))\n",
        "    classified_data['True label'] = \"\"\n",
        "    classified_data['Comments'] = \"\"\n",
        "    classified_data['Requires expert review'] = False\n",
        "\n",
        "    # Select the relevant columns for the review table\n",
        "    return classified_data[['Index', 'Abstract', 'Reviewer', 'True label', 'Comments', 'Requires expert review']]\n",
        "\n",
        "\n",
        "def assign_reviewers(num_cases):\n",
        "    \"\"\"\n",
        "    Assign reviewers to cases in a round-robin fashion.\n",
        "\n",
        "    Args:\n",
        "        num_cases (int): Number of cases to review.\n",
        "\n",
        "    Returns:\n",
        "        list: Reviewer assignments.\n",
        "    \"\"\"\n",
        "    reviewers = ['Rohan', 'Raymond', 'Lior', 'Jamie', 'Zara', 'Johanna']\n",
        "    return [reviewers[i % len(reviewers)] for i in range(num_cases)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6cef53",
      "metadata": {
        "id": "ba6cef53"
      },
      "source": [
        "# Main Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2769f3d7",
      "metadata": {
        "id": "2769f3d7",
        "outputId": "999587c8-d766-48e1-aa84-80d9f5217e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered down to 4853 abstracts containing relevant keywords.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m keywords \u001b[38;5;241m=\u001b[39m industry_keywords[industry]\n\u001b[0;32m      5\u001b[0m total_abstracts_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./required_files/total_abstracts_df_sets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m classified_data \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_patents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_abstracts_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindustry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save a balanced dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m balanced_data \u001b[38;5;241m=\u001b[39m save_balanced_csv(classified_data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindustry\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, industry)\n",
            "Cell \u001b[1;32mIn[7], line 36\u001b[0m, in \u001b[0;36mclassify_patents\u001b[1;34m(data, industry, keywords, few_shot_examples, max_positives, rpm, use_filter)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_industry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabstract\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindustry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     data\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLM Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m prediction\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mpredict_industry\u001b[1;34m(abstract, industry, keywords, few_shot_examples, max_retries, delay)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempts \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# Make a single API call with the refined prompt\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m         response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Exit loop if request is successful\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\grpc\\_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1175\u001b[0m     (\n\u001b[0;32m   1176\u001b[0m         state,\n\u001b[0;32m   1177\u001b[0m         call,\n\u001b[1;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\Zara\\anaconda3\\envs\\testing\\lib\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Change industry to the one we are doing\n",
        "industry = \"Autonomous Vehicles\"\n",
        "keywords = industry_keywords[industry]\n",
        "\n",
        "total_abstracts_df = pd.read_csv('./required_files/total_abstracts_df_sets.csv')\n",
        "\n",
        "classified_data = classify_patents(total_abstracts_df, industry, keywords, few_shot_examples, rpm=2000)\n",
        "\n",
        "# Save a balanced dataset\n",
        "balanced_data = save_balanced_csv(classified_data, f\"balanced_{industry.lower().replace(' ', '_')}_dataset.csv\", industry)\n",
        "\n",
        "\n",
        "review_table = prepare_review_table(classified_data)\n",
        "review_table.to_csv('classified_review_set.csv', index=False)\n",
        "\n",
        "positive_examples = classified_data[classified_data['LLM Prediction'] == 'Yes']\n",
        "positive_indexes = positive_examples['Patent ID'].tolist()  # List of positive classification indexes\n",
        "print(\"Indexes of 40 positive classifications:\", positive_indexes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2484578d",
      "metadata": {
        "id": "2484578d"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7e3d674c",
      "metadata": {
        "id": "7e3d674c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# function that calculates metrics of performance\n",
        "# model_table parameter: table of model classifications with a column \"prediction\".\n",
        "# true_table: table of true labels with a column \"true_label\"\n",
        "# returns: Dictionary containing precision, recall, accuracy, and confusion matrix.\n",
        "def calculate_metrics(model_table, true_table):\n",
        "\n",
        "    # ensure both tables have an index column that indexes each unique patent abstract\n",
        "    if 'Index' not in model_table.columns or 'Index' not in true_table.columns:\n",
        "        raise ValueError(\"Both tables must have an 'Index' column to perform a join.\")\n",
        "\n",
        "    # perform an inner join on the index column to match predictions with true labels\n",
        "    merged_table = pd.merge(model_table, true_table, on='Index', how='inner')\n",
        "\n",
        "    # extract predictions + true labels\n",
        "    predictions = merged_table['Prediction'].str.strip().str.title()\n",
        "    true_labels = merged_table['True label'].str.strip().str.title()\n",
        "\n",
        "    # calculate metrics\n",
        "    precision = precision_score(true_labels, predictions, pos_label='Yes', zero_division=0)\n",
        "    recall = recall_score(true_labels, predictions, pos_label='Yes', zero_division=0)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    baseline_accuracy = (true_labels == true_labels.mode()[0]).mean()\n",
        "    lift = accuracy / baseline_accuracy\n",
        "\n",
        "    conf_matrix = confusion_matrix(true_labels, predictions, labels=['No', 'Yes'])\n",
        "    TN, FP, FN, TP = conf_matrix.ravel()\n",
        "\n",
        "    # return results in a dictionary\n",
        "    metrics = {\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'Accuracy': accuracy,\n",
        "        'Baseline Accuracy': baseline_accuracy,\n",
        "        'Lift': lift,\n",
        "        'Confusion Matrix': conf_matrix,\n",
        "        'True Negatives (TN)': TN,\n",
        "        'False Positives (FP)': FP,\n",
        "        'False Negatives (FN)': FN,\n",
        "        'True Positives (TP)': TP,\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3e2840df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e2840df",
        "outputId": "ff1154ba-e955-4028-8e7d-c63e7753bb27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Precision': 0.325, 'Recall': 0.5909090909090909, 'Accuracy': 0.9394957983193277, 'Baseline Accuracy': 0.9630252100840336, 'Lift': 0.9755671902268761, 'Confusion Matrix': array([[546,  27],\n",
            "       [  9,  13]]), 'True Negatives (TN)': 546, 'False Positives (FP)': 27, 'False Negatives (FN)': 9, 'True Positives (TP)': 13}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "classified_review_set = pd.read_csv('sample_data/classified_review_set.csv')\n",
        "\n",
        "model_table = classified_review_set[['Index', 'Prediction']]\n",
        "true_table = classified_review_set[['Index', 'True label']]\n",
        "\n",
        "# calculate + print metrics\n",
        "metrics = calculate_metrics(model_table, true_table)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "839eE1VCoL6u"
      },
      "id": "839eE1VCoL6u",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "testing",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}